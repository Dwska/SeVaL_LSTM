{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabf4317-7fd0-45cf-9464-1d049add8bea",
   "metadata": {},
   "source": [
    "# 1. Import library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "f4505d26-26ef-4453-b525-a3f8f669204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "c8000832-0c39-430a-8862-4b3a81d16e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training Dataset\n",
    "df_train = pd.read_csv('./Dataset_DL/english_dataset/train/eng_t_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "2789c01d-0055-455d-92f6-e4f456bdeb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19474f-1c1f-449c-a897-8023dedeba96",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "77c36cee-c46d-4881-b34d-a5e0ddeff918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but not very happy i love this product it amazing and work perfectly\n"
     ]
    }
   ],
   "source": [
    "# Function to remove noise and normalize text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Example text\n",
    "text = \"But not very happy. I love this product! It's amazing, and works perfectly.\"\n",
    "\n",
    "# Preprocess text\n",
    "cleaned_text = preprocess_text(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "f7b700de-84e8-48a0-8383-e1b6e1630769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocess_text function to the 'text' column \n",
    "df_train['cleaned_text'] = df_train['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "665e23ac-707e-4e25-80ea-94b2491f9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text and labels \n",
    "X = df_train['cleaned_text'] \n",
    "y = df_train[['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "15a1d331-ce40-406b-a96e-bc8125ddc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "e5f1b1ca-eea7-4d8f-8377-642165617aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text data\n",
    "vocab_size = 10000  # Set a vocabulary size\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "9a2a8df3-d5be-46a2-a9ea-ee8520f730f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = 100  # Fixed max length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040e959-0bbe-44d1-be8f-d38af4b12b40",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "d753af16-a266-4264-bdab-6687954e1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=128))\n",
    "    model.add(LSTM(units=hp.Int('lstm_units_1', min_value=64, max_value=256, step=32), return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('lstm_units_2', min_value=32, max_value=128, step=16), return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_units', min_value=16, max_value=128, step=16), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout_3', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=5, activation='sigmoid'))  # Multi-class classification when the labels are Multiple, independent labels\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "72c0b0eb-4400-4c01-adf7-c33134afed6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_26 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_27 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m165\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,464,005</span> (5.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,464,005\u001b[0m (5.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,463,621</span> (5.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,463,621\u001b[0m (5.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "b3aa6009-d65a-430f-a257-89461f8be92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Keras Tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_results',\n",
    "    project_name='sentiment_analysis_lstm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "35a08cf2-eadf-4c17-9e6c-0d30bebb5332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 01s]\n",
      "val_accuracy: 0.5150421261787415\n",
      "\n",
      "Best val_accuracy So Far: 0.5162454843521118\n",
      "Total elapsed time: 00h 10m 56s\n"
     ]
    }
   ],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test_padded, y_test),\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "a86492a8-7a22-49d1-a768-f79529f4961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - accuracy: 0.3599 - loss: 0.6390 - val_accuracy: 0.5150 - val_loss: 0.6107\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.5062 - loss: 0.5814 - val_accuracy: 0.5150 - val_loss: 0.5919\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.4795 - loss: 0.5827 - val_accuracy: 0.5150 - val_loss: 0.5770\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - accuracy: 0.5051 - loss: 0.5745 - val_accuracy: 0.5150 - val_loss: 0.5725\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 276ms/step - accuracy: 0.4802 - loss: 0.5780 - val_accuracy: 0.5150 - val_loss: 0.5698\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.4897 - loss: 0.5747 - val_accuracy: 0.5150 - val_loss: 0.5691\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 279ms/step - accuracy: 0.4979 - loss: 0.5677 - val_accuracy: 0.5150 - val_loss: 0.5712\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.4763 - loss: 0.5746 - val_accuracy: 0.5150 - val_loss: 0.5675\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.5069 - loss: 0.5707 - val_accuracy: 0.5150 - val_loss: 0.5692\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.4993 - loss: 0.5653 - val_accuracy: 0.5150 - val_loss: 0.5694\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = best_model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test_padded, y_test),\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56bcaa-6a62-4c87-baa9-349312018c04",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "064c2f8e-2e82-411f-891b-17cc828dfb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.5117 - loss: 0.5685\n",
      "Test Accuracy: 0.5150421261787415\n",
      "Best Hyperparameters: {'lstm_units_1': 256, 'dropout_1': 0.4, 'lstm_units_2': 48, 'dropout_2': 0.30000000000000004, 'dense_units': 128, 'dropout_3': 0.2, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "268fb11a-4aa9-4527-a092-d867731366d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessary if it run locally\n",
    "# Save the trained model \n",
    "best_model.save('./Model/sentiment_analysis_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c85dc-baae-4a21-8ed9-12481e1372fa",
   "metadata": {},
   "source": [
    "# Inferencing unlabeled dataset for the real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "07c4bbce-1478-405b-8cfe-f7cead25d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Testing Dataset\n",
    "df_test = pd.read_csv('./Dataset_DL/english_dataset/test/eng_a.csv')\n",
    "\n",
    "df_test_top = df_test[['id', 'text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "a735c818-42c6-4fd6-8a08-9b9613808c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocess_text function to the 'text' column \n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "f11e59c6-320e-4119-ac7f-9abb05034dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data \n",
    "vocab_size = 10000  # Set a vocabulary size\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>') \n",
    "tokenizer.fit_on_texts(df_test['text']) \n",
    "new_sequences = tokenizer.texts_to_sequences(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "af3ff4da-2408-4702-9fa7-9254e2e9fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = 100  # Fixed max length\n",
    "new_padded = pad_sequences(new_sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "cdc8f8d6-4d2d-43ca-affb-a33c416d09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessary if it run locally\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model \n",
    "#model = load_model('./Model/sentiment_analysis_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa0b47-d495-4b03-8e77-8e6518e85a6c",
   "metadata": {},
   "source": [
    "## Using the threshold 0.5 to classify whether an emotion is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "676d5f8d-cf6d-4eb5-99bf-665f2b7e62b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the new data \n",
    "predictions = best_model.predict(new_padded)\n",
    "\n",
    "# Define a threshold for classification\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert predictions to readable format \n",
    "predicted_labels = (predictions > threshold).astype(int)\n",
    "\n",
    "# Combine with the new dataset \n",
    "df_test[['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "ce40774a-458f-4cc2-bb1e-608f91f62223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13138212 0.5473095  0.28300503 0.342344   0.3279194 ]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.3279194 ]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.3279194 ]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.32791942]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.32791942]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.32791942]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.32791942]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.32791942]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.3279194 ]\n",
      "[0.13138212 0.5473095  0.28300503 0.342344   0.32791942]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "43ad17f1-b15a-4f58-a149-0abee44eb397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_dev_track_a_00001</td>\n",
       "      <td>my mouth fell open no no no i</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_dev_track_a_00002</td>\n",
       "      <td>you can barely make out your daughter pale for...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_dev_track_a_00003</td>\n",
       "      <td>but after blinking my eye for a few time lepas...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_dev_track_a_00004</td>\n",
       "      <td>slowly rising to my foot i came to the conclus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_dev_track_a_00005</td>\n",
       "      <td>i noticed this month after moving in and doing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>eng_dev_track_a_00112</td>\n",
       "      <td>arch stop your progression</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>eng_dev_track_a_00113</td>\n",
       "      <td>this star start to move across the sky</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>eng_dev_track_a_00114</td>\n",
       "      <td>and my foot hurt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>eng_dev_track_a_00115</td>\n",
       "      <td>so i cried my eye out and did the drawing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>eng_dev_track_a_00116</td>\n",
       "      <td>they were coal black</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0    eng_dev_track_a_00001                      my mouth fell open no no no i   \n",
       "1    eng_dev_track_a_00002  you can barely make out your daughter pale for...   \n",
       "2    eng_dev_track_a_00003  but after blinking my eye for a few time lepas...   \n",
       "3    eng_dev_track_a_00004  slowly rising to my foot i came to the conclus...   \n",
       "4    eng_dev_track_a_00005  i noticed this month after moving in and doing...   \n",
       "..                     ...                                                ...   \n",
       "111  eng_dev_track_a_00112                         arch stop your progression   \n",
       "112  eng_dev_track_a_00113             this star start to move across the sky   \n",
       "113  eng_dev_track_a_00114                                   and my foot hurt   \n",
       "114  eng_dev_track_a_00115          so i cried my eye out and did the drawing   \n",
       "115  eng_dev_track_a_00116                               they were coal black   \n",
       "\n",
       "     Anger  Fear  Joy  Sadness  Surprise  \n",
       "0        0     1    0        0         0  \n",
       "1        0     1    0        0         0  \n",
       "2        0     1    0        0         0  \n",
       "3        0     1    0        0         0  \n",
       "4        0     1    0        0         0  \n",
       "..     ...   ...  ...      ...       ...  \n",
       "111      0     1    0        0         0  \n",
       "112      0     1    0        0         0  \n",
       "113      0     1    0        0         0  \n",
       "114      0     1    0        0         0  \n",
       "115      0     1    0        0         0  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "ae005a6e-4dae-4b8f-87b3-487f4a6c4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of value 1 in each label column:\n",
      "Anger: 0\n",
      "Fear: 116\n",
      "Joy: 0\n",
      "Sadness: 0\n",
      "Surprise: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of 1 in each label column \n",
    "anger_count = df_test['Anger'].sum() \n",
    "fear_count = df_test['Fear'].sum() \n",
    "joy_count = df_test['Joy'].sum() \n",
    "sadness_count = df_test['Sadness'].sum() \n",
    "surprise_count = df_test['Surprise'].sum()\n",
    "\n",
    "print(\"Count of value 1 in each label column:\") \n",
    "print(f\"Anger: {anger_count}\") \n",
    "print(f\"Fear: {fear_count}\") \n",
    "print(f\"Joy: {joy_count}\") \n",
    "print(f\"Sadness: {sadness_count}\") \n",
    "print(f\"Surprise: {surprise_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f1e1d-0679-4824-ad56-46a2f729f3b5",
   "metadata": {},
   "source": [
    "## Using TOP-N Selection as the most likely emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "34f7ee11-7f53-46e9-86af-bef5e870ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define emotions corresponding to model output columns\n",
    "emotions = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
    "\n",
    "# Number of top emotions to select\n",
    "top_n = 2\n",
    "\n",
    "# Function to get the top-N emotions for each prediction row\n",
    "def get_top_n_emotions(prediction_row, emotions, top_n):\n",
    "    # Get indices of top-N emotions\n",
    "    top_indices = prediction_row.argsort()[-top_n:][::-1]\n",
    "    # Map indices to emotion names\n",
    "    return [emotions[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "d47644c8-4c70-4e85-9b6e-c9a38db08961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to all predictions\n",
    "df_test_top['Top_2_Emotions'] = [get_top_n_emotions(row, emotions, top_n) for row in predictions]\n",
    "\n",
    "# (Optional) Add probabilities of the top-N emotions\n",
    "df_test_top['Top_2_Probs'] = [sorted(row, reverse=True)[:top_n] for row in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "dc5b0951-6f1f-460f-aa6a-e7c7924433b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Top_2_Emotions              Top_2_Probs\n",
      "0    [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "1    [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "2    [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "3    [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "4    [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "..               ...                      ...\n",
      "111  [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "112  [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "113  [Fear, Sadness]  [0.5473095, 0.34234402]\n",
      "114  [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "115  [Fear, Sadness]    [0.5473095, 0.342344]\n",
      "\n",
      "[116 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Optional: Display the DataFrame\n",
    "print(df_test_top[['Top_2_Emotions', 'Top_2_Probs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "5e2aca70-8b97-4f84-8236-378d99f8fce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Top_2_Emotions</th>\n",
       "      <th>Top_2_Probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_dev_track_a_00001</td>\n",
       "      <td>My mouth fell open `` No, no, no... I..</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_dev_track_a_00002</td>\n",
       "      <td>You can barely make out your daughter's pale f...</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_dev_track_a_00003</td>\n",
       "      <td>But after blinking my eyes for a few times lep...</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_dev_track_a_00004</td>\n",
       "      <td>Slowly rising to my feet I came to the conclus...</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_dev_track_a_00005</td>\n",
       "      <td>I noticed this months after moving in and doin...</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>eng_dev_track_a_00112</td>\n",
       "      <td>\"ARcH stop your progression.</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>eng_dev_track_a_00113</td>\n",
       "      <td>This 'star', starts to move across the sky.</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>eng_dev_track_a_00114</td>\n",
       "      <td>and my feet hurt.</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.34234402]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>eng_dev_track_a_00115</td>\n",
       "      <td>so i cried my eyes out and did the drawing.</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>eng_dev_track_a_00116</td>\n",
       "      <td>They were coal black.</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "      <td>[0.5473095, 0.342344]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0    eng_dev_track_a_00001            My mouth fell open `` No, no, no... I..   \n",
       "1    eng_dev_track_a_00002  You can barely make out your daughter's pale f...   \n",
       "2    eng_dev_track_a_00003  But after blinking my eyes for a few times lep...   \n",
       "3    eng_dev_track_a_00004  Slowly rising to my feet I came to the conclus...   \n",
       "4    eng_dev_track_a_00005  I noticed this months after moving in and doin...   \n",
       "..                     ...                                                ...   \n",
       "111  eng_dev_track_a_00112                       \"ARcH stop your progression.   \n",
       "112  eng_dev_track_a_00113        This 'star', starts to move across the sky.   \n",
       "113  eng_dev_track_a_00114                                  and my feet hurt.   \n",
       "114  eng_dev_track_a_00115        so i cried my eyes out and did the drawing.   \n",
       "115  eng_dev_track_a_00116                              They were coal black.   \n",
       "\n",
       "      Top_2_Emotions              Top_2_Probs  \n",
       "0    [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "1    [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "2    [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "3    [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "4    [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "..               ...                      ...  \n",
       "111  [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "112  [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "113  [Fear, Sadness]  [0.5473095, 0.34234402]  \n",
       "114  [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "115  [Fear, Sadness]    [0.5473095, 0.342344]  \n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85515c16-48a8-48e8-bc0a-eb8e0b0c23c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PersonalProjects",
   "language": "python",
   "name": "personalprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
